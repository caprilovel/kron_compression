{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from gkpd.tensorops import kron\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003479146957397461 0.0019947799501378533\n"
     ]
    }
   ],
   "source": [
    "cal_time = []\n",
    "for i in enumerate(range(100)):\n",
    "    a = torch.randn(10000,10000)\n",
    "    b = torch.randn(10000,10000)\n",
    "    a = a.cuda()\n",
    "    b = b.cuda()\n",
    "    start = time.time()\n",
    "    c = torch.matmul(a,b)\n",
    "    end = time.time()\n",
    "    cal_time.append(end-start)\n",
    "cal_time = np.array(cal_time)\n",
    "print(np.mean(cal_time), np.std(cal_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00013594865798950196 1.608695843083442e-05\n"
     ]
    }
   ],
   "source": [
    "# keep the same size, but a have a sparsity of 0.1\n",
    "sparsity = 0.1\n",
    "a = torch.randn(10000,10000)\n",
    "a_shape = a.flatten().shape[0]\n",
    "sparse_time = []\n",
    "mask = torch.cat([torch.zeros(int(a_shape*sparsity)), torch.ones(int(a_shape*(1-sparsity)))])\n",
    "mask = mask[torch.randperm(a_shape)]\n",
    "mask = mask.reshape(a.shape)\n",
    "for i in enumerate(range(100)):\n",
    "    a = torch.randn(10000,10000)\n",
    "    b = torch.randn(10000,10000)\n",
    "    a = a * mask\n",
    "    a = a.cuda()\n",
    "    b = b.cuda()\n",
    "    start = time.time()\n",
    "    c = torch.matmul(a,b)\n",
    "    end = time.time()\n",
    "    sparse_time.append(end-start)\n",
    "sparse_time = np.array(sparse_time)\n",
    "print(np.mean(sparse_time), np.std(sparse_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(100, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1+cu121'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "def quick_kron(tensora, tensorb):\n",
    "    \"\"\"a quick kronecker product for two tensors\n",
    "\n",
    "    For example, Tensor A of size [x1, y1] kronecker product with Tensor B of size [x2, y2], will get a tensor of size [x1*x2, y1*y2]. This can be extend to multiple dimension two tensors.     \n",
    "    Args:\n",
    "        tensora (_type_): Tensor Matrix A\n",
    "        tensorb (_type_): Tensor Matrix B\n",
    "    \"\"\"\n",
    "    a_shape = np.array(tensora.shape)\n",
    "    b_shape = np.array(tensorb.shape)\n",
    "    out_shape = np.multiply(a_shape, b_shape)\n",
    "    return  torch.einsum('ik,jl', tensora, tensorb).reshape(*out_shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02580547332763672\n",
      "0.009335994720458984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]], device='cuda:1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "device = torch.device('cuda:1')\n",
    "x1 = torch.randn(10, 10)\n",
    "x2 = torch.randn(15, 10)\n",
    "x1 = x1.to(device)\n",
    "x2 = x2.to(device)\n",
    "start1 = time.time()\n",
    "x3 = torch.kron(x1, x2)\n",
    "end1 = time.time()\n",
    "print(end1-start1)\n",
    "start2 = time.time()\n",
    "x4 = quick_kron(x1, x2)\n",
    "end2 = time.time()\n",
    "print(end2-start2)\n",
    "x3==x4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
