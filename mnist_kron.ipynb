{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from einops import rearrange, reduce, repeat\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch \n",
    "from gkpd import gkpd, KroneckerConv2d\n",
    "from gkpd.tensorops import kron\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4096])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class KronLinear(nn.Module):\n",
    "    def __init__(self, rank, a_shape, b_shape, bias=True) -> None:\n",
    "        super().__init__()\n",
    "        self.rank = rank\n",
    "        self.s = nn.Parameter(torch.randn(*a_shape), requires_grad=True)\n",
    "        self.a = nn.Parameter(torch.randn(rank, *a_shape), requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.randn(rank, *b_shape), requires_grad=True)\n",
    "        nn.init.xavier_uniform_(self.a)\n",
    "        nn.init.xavier_uniform_(self.b)\n",
    "        bias_shape = np.multiply(a_shape, b_shape)\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(*bias_shape[1:]), requires_grad=True)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        a = self.s.unsqueeze(0) * self.a\n",
    "        w = kron(a, self.b)\n",
    "        \n",
    "        out = x @ w \n",
    "        if self.bias is not None:\n",
    "            out += self.bias.unsqueeze(0)\n",
    "        return out\n",
    "    \n",
    "# test module \n",
    "x = torch.randn(64, 256)\n",
    "m = KronLinear(10, (16, 64), (16, 64), bias=False)\n",
    "\n",
    "m(x).shape \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        \n",
    "class KronLeNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(KronLeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        rank1 = 21\n",
    "        rank2 = 10\n",
    "        rank3 = 4\n",
    "    \n",
    "        self.kronfc1 = KronLinear(rank1, (16, 10), (16, 12), bias=False)\n",
    "        \n",
    "        self.kronfc2 = KronLinear(rank2, (10, 12), (12, 7), bias=False)\n",
    "        self.kronfc3 = KronLinear(rank3, (12, 2), (7, 5), bias=False)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = self.relu3(self.kronfc1(x))\n",
    "        x = self.relu4(self.kronfc2(x))\n",
    "        x = self.kronfc3(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kl = KronLinear(2, (2, 2), (2, 2), bias=False)\n",
    "# optimizer = optim.Adam(kl.parameters(), lr=0.001)\n",
    "# for i in kl.parameters():\n",
    "#     print(i)\n",
    "# x = torch.randn(2, 4)\n",
    "# y = torch.randint(0, 2, (2, ))\n",
    "# kl(x).shape\n",
    "# loss = F.cross_entropy(kl(x), y)\n",
    "# loss.backward()\n",
    "\n",
    "# for i in kl.parameters():\n",
    "#     print(i.grad.numpy())\n",
    "# optimizer.step()\n",
    "# for i in kl.parameters():\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.relu4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# calculate the number of parameters in LeNet\n",
    "def count_parameter(model):\n",
    "    \n",
    "    total = 0\n",
    "    for i in model.parameters():\n",
    "        total += i.numel()\n",
    "    print(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12544\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = KronLeNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "count_parameter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inputs, labels in train_loader:\n",
    "#     inputs, labels = inputs.to(device), labels.to(device)\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = model(inputs)\n",
    "#     loss = criterion(outputs, labels)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     break\n",
    "# loss\n",
    "# for i in model.parameters():\n",
    "#     print(i.shape)\n",
    "# model.kronfc1.a.grad.cpu().numpy()\n",
    "def calculate_sparsity(model, threshold=1e-6):\n",
    "    total_params = 0\n",
    "    sparse_params = 0\n",
    "\n",
    "    for param in model.parameters():\n",
    "        total_params += param.numel()  # 统计参数总数\n",
    "        sparse_params += torch.sum(torch.abs(param) < threshold).item()  # 统计绝对值小于阈值的参数数量\n",
    "\n",
    "    sparsity = sparse_params / total_params  # 计算稀疏性\n",
    "    return sparsity, sparse_params, total_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epochs, l1_weight=0.01):\n",
    "    decay_weight = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "    weight1 = l1_weight\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        l1_weight = decay_weight[epoch//20] * weight1\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs, outputs.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss += l1_weight * torch.norm(model.kronfc1.s, p=1)\n",
    "            loss += l1_weight * torch.norm(model.kronfc2.s, p=1)\n",
    "            loss += l1_weight * torch.norm(model.kronfc3.s, p=1)\n",
    "            \n",
    "            # print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "        # print the sparsity of a, dont use == use the abs less than 1e-5\n",
    "        print(calculate_sparsity(model))\n",
    "        # calcu the s sparsity\n",
    "        fc1_sparse = torch.sum(torch.abs(model.kronfc1.s) < 1e-5).item() \n",
    "        fc2_sparse = torch.sum(torch.abs(model.kronfc2.s) < 1e-5).item() \n",
    "        fc3_sparse = torch.sum(torch.abs(model.kronfc3.s) < 1e-5).item() \n",
    "        # total_params = model.kronfc1.s.numel() + model.kronfc2.s.numel() + model.kronfc3.s.numel()\n",
    "        \n",
    "        print(f\"fc1 sparsity: {fc1_sparse}, fc2 sparsity: {fc2_sparse}, fc3 sparsity: {fc3_sparse}\")\n",
    "        print(f\"total sparse params: {fc1_sparse + fc2_sparse + fc3_sparse}\")\n",
    "        # print(f\"fc1 total params: {model.kronfc1.s.numel()}, fc2 total params: {model.kronfc2.s.numel()}, fc3 total params: {model.kronfc3.s.numel()}\")\n",
    "        # print(f\"total params: {total_params}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, criterion, optimizer, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "    print(f\"Accuracy: {100 * correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.45999908447266\n"
     ]
    }
   ],
   "source": [
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KronLeNet' object has no attribute 'fc1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m weight1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m      2\u001b[0m weight2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m      3\u001b[0m weight3 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc3\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KronLeNet' object has no attribute 'fc1'"
     ]
    }
   ],
   "source": [
    "weight1 = model.fc1.weight.data.detach()\n",
    "weight2 = model.fc2.weight.data.detach()\n",
    "weight3 = model.fc3.weight.data.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21644"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcu the nums of the three weight matrix\n",
    "params = 0\n",
    "for i in model.parameters():\n",
    "    params += i.numel()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 256]) torch.Size([84, 120]) torch.Size([10, 84])\n"
     ]
    }
   ],
   "source": [
    "print(weight1.shape, weight2.shape, weight3.shape)\n",
    "w11_shape = [10, 16] \n",
    "w12_shape = [12, 16]\n",
    "w21_shape = [7, 12]\n",
    "w22_shape = [12, 10]\n",
    "w31_shape = [5, 7]\n",
    "w32_shape = [2, 12]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([152, 10, 16]),\n",
       " torch.Size([152, 12, 16]),\n",
       " torch.Size([84, 7, 12]),\n",
       " torch.Size([84, 12, 10]),\n",
       " torch.Size([24, 5, 7]),\n",
       " torch.Size([24, 2, 12]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = 50 # 160\n",
    "w11_hat, w12_hat = gkpd(weight1, w11_shape, w12_shape, atol=1e-1)\n",
    "r2 = 31 # 84\n",
    "w21_hat, w22_hat = gkpd(weight2, w21_shape, w22_shape, atol=1e-1)\n",
    "r3 = 8 # 24\n",
    "w31_hat, w32_hat = gkpd(weight3, w31_shape, w32_shape, atol=1e-1)\n",
    "w11_hat.shape, w12_hat.shape, w21_hat.shape, w22_hat.shape, w31_hat.shape, w32_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24396"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcu the nums of the six weight matrix\n",
    "params = 0\n",
    "for i in [w11_hat[0:r1,], w12_hat[0:r1,], w21_hat[0:r2,], w22_hat[0:r2,], w31_hat[0:r3,], w32_hat[0:r3,]]:\n",
    "    params += i.numel()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.9000015258789\n"
     ]
    }
   ],
   "source": [
    "w1_hat = kron(w11_hat[0:r1], w12_hat[0:r1])\n",
    "w2_hat = kron(w21_hat[0:r2], w22_hat[0:r2]) \n",
    "w3_hat = kron(w31_hat[0:r3], w32_hat[0:r3])\n",
    "model.fc1.weight.data = w1_hat\n",
    "model.fc2.weight.data = w2_hat\n",
    "model.fc3.weight.data = w3_hat\n",
    "model = model.to(device)\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w111_shape, w112_shape = [16, 2, 4], [10, 5, 4]\n",
    "w211_shape, w212_shape = [28, 1, 3], [3, 7, 4]\n",
    "w311_shape, w312_shape = [4, 1, 7], [6, 5, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = 64 # 128\n",
    "w111_hat, w112_hat = gkpd(w11_hat, w111_shape, w112_shape)\n",
    "r2 = 41 # 83\n",
    "w211_hat, w212_hat = gkpd(w21_hat, w211_shape, w212_shape)\n",
    "w211_hat.shape\n",
    "r3 = 14 # 28\n",
    "w311_hat, w312_hat = gkpd(w31_hat, w311_shape, w312_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70068"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcu the nums of the 9 weight matrix\n",
    "params = 0\n",
    "for i in [w111_hat[0:r1,], w112_hat[0:r1,], w211_hat[0:r2,], w212_hat[0:r2,], w311_hat[0:r3,], w312_hat[0:r3,]]:\n",
    "    params += i.numel()\n",
    "for i in [w12_hat, w22_hat, w32_hat]:\n",
    "    params += i.numel()\n",
    "params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_transpose(param):\n",
    "    N,_,_ = param.shape\n",
    "    return torch.reshape(param, (N, -1)).T\n",
    "a = torch.randn(2, 3, 4)\n",
    "group_transpose(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "import time\n",
    "\n",
    "def factorize(n: int) -> List[int]:\n",
    "    \"\"\"Return the most average two factorization of n.\"\"\"\n",
    "    for i in range(int(np.sqrt(n)) + 1, 1, -1):\n",
    "        if n % i == 0:\n",
    "            return [i, n // i]\n",
    "    return [n, 1]\n",
    "\n",
    "class KronLinear(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, rank=0, structured_sparse=False, bias=True) -> None:\n",
    "        \"\"\"Kronecker Linear Layer\n",
    "\n",
    "        the weight matrix is a kron(a, b) matrix\n",
    "        \n",
    "        Args:\n",
    "            rank (int): the rank of the Kronecker product\n",
    "            a_shape (tuple): the shape of the **a** matrix \n",
    "            b_shape (tuple): the shape of the **b** matrix\n",
    "            structured_sparse (bool, optional): _description_. Defaults to False.\n",
    "            bias (bool, optional): _description_. Defaults to True.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        input_dims = factorize(input_dim)\n",
    "        output_dims = factorize(output_dim)\n",
    "\n",
    "        if rank == 0:\n",
    "            rank = min(*input_dims, *output_dims) // 2 + 1\n",
    "        self.rank = rank\n",
    "        \n",
    "        a_shape = [input_dims[0], output_dims[1]]\n",
    "        b_shape = [input_dims[1], output_dims[0]]\n",
    "        \n",
    "\n",
    "        self.structured_sparse = structured_sparse\n",
    "        if structured_sparse:\n",
    "            self.s = nn.Parameter(torch.randn( *a_shape), requires_grad=True)\n",
    "        self.a = nn.Parameter(torch.randn(rank, *a_shape), requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.randn(rank, *b_shape), requires_grad=True)\n",
    "        self.a_shape = self.a.shape\n",
    "        self.b_shape = self.b.shape\n",
    "\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.a)\n",
    "        nn.init.xavier_uniform_(self.b)\n",
    "        bias_shape = np.multiply(a_shape, b_shape)\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(*bias_shape[1:]), requires_grad=True)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        start_time = time.time()\n",
    "        a = self.a\n",
    "        if self.structured_sparse:\n",
    "            a = self.s.unsqueeze(0) * self.a\n",
    "        \n",
    "        # a = self.s.unsqueeze(0) * self.a\n",
    "        # w = kron(a, self.b)\n",
    "        x_shape = x.shape \n",
    "        b = self.b\n",
    "        \n",
    "        x = torch.reshape(x, (-1, x_shape[-1]))\n",
    "        b = rearrange(b, 'r b1 b2 -> b1 (b2 r)')\n",
    "        temp_time1 = time.time()\n",
    "        x = rearrange(x, 'n (a1 b1) -> n a1 b1', a1=self.a_shape[1], b1=self.b_shape[1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        out = x @ b\n",
    "        out = rearrange(out, 'n a1 (b2 r) -> r (n b2) a1', b2=self.b_shape[2], r=self.rank)\n",
    "        out = torch.bmm(out, a)\n",
    "        \n",
    "        temp_time2 = time.time()\n",
    "        out = torch.sum(out, dim=0).squeeze(0)\n",
    "        out = rearrange(out, '(n b2) a2 -> n (a2 b2)', b2=self.b_shape[2])\n",
    "        out = torch.reshape(out, x_shape[:-1] + (self.a_shape[2] * self.b_shape[2],))\n",
    "        \n",
    "        temp_time3 = time.time()\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            out += self.bias.unsqueeze(0)\n",
    "        print(f\"temp1: {temp_time1 - start_time}, temp2: {temp_time2 - temp_time1}, temp3: {temp_time3 - temp_time2}\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_time: 0.17915916442871094\n",
      "temp1: 1.0572125911712646, temp2: 0.020016908645629883, temp3: 0.042214393615722656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0998e+00, -7.8515e-02, -9.2896e-02,  ..., -9.3900e-01,\n",
       "           2.2467e-01, -1.4432e+00],\n",
       "         [ 1.4162e+00, -2.1176e-01, -6.8326e-01,  ..., -1.3719e+00,\n",
       "           1.4165e-01, -1.9268e+00],\n",
       "         [ 2.2396e+00, -6.5502e-01, -6.1903e-01,  ..., -7.6443e-01,\n",
       "           2.7660e-01, -2.4048e+00],\n",
       "         ...,\n",
       "         [ 2.2934e+00, -7.6379e-01, -4.9580e-01,  ..., -1.6205e+00,\n",
       "           2.5274e-02, -1.3255e+00],\n",
       "         [ 1.2249e+00, -8.3870e-01, -1.8488e-01,  ..., -1.3832e+00,\n",
       "           3.5246e-01, -2.1933e+00],\n",
       "         [ 1.8619e+00, -1.7207e-01, -1.2606e-01,  ..., -8.4862e-01,\n",
       "          -3.4171e-01, -1.8930e+00]],\n",
       "\n",
       "        [[ 1.2569e+00, -2.4066e-01, -2.0012e-01,  ..., -1.2331e+00,\n",
       "           1.6825e-01, -1.8048e+00],\n",
       "         [ 2.3396e+00, -6.2259e-01, -2.4804e-01,  ..., -1.0605e+00,\n",
       "          -9.6438e-02, -1.9671e+00],\n",
       "         [ 1.1657e+00, -5.9814e-01, -1.7428e-01,  ..., -1.5358e+00,\n",
       "           1.4133e-01, -2.0794e+00],\n",
       "         ...,\n",
       "         [ 2.5432e+00, -7.5636e-01,  8.3385e-02,  ..., -1.1828e+00,\n",
       "          -4.5535e-02, -1.3953e+00],\n",
       "         [ 2.0329e+00, -1.8979e-01, -1.9567e-01,  ..., -5.2573e-01,\n",
       "          -2.4461e-01, -2.0897e+00],\n",
       "         [ 1.8912e+00, -4.4590e-01, -6.7664e-01,  ..., -9.9311e-01,\n",
       "           1.3860e-01, -2.0937e+00]],\n",
       "\n",
       "        [[ 1.6516e+00, -4.6396e-01, -8.7216e-01,  ..., -1.3523e+00,\n",
       "          -2.7135e-02, -2.0830e+00],\n",
       "         [ 1.8524e+00, -4.2845e-01,  6.1504e-01,  ..., -1.3924e+00,\n",
       "          -2.5673e-01, -1.4705e+00],\n",
       "         [ 1.5013e+00, -5.2135e-01,  7.4169e-02,  ..., -1.3687e+00,\n",
       "          -8.9343e-02, -2.0935e+00],\n",
       "         ...,\n",
       "         [ 1.9678e+00,  6.3878e-04, -1.6409e-01,  ..., -1.4515e+00,\n",
       "           1.3898e-01, -1.2667e+00],\n",
       "         [ 1.7795e+00, -4.9337e-01, -5.7485e-01,  ..., -1.1490e+00,\n",
       "          -8.2852e-02, -2.3823e+00],\n",
       "         [ 1.2314e+00, -1.6168e-01, -5.0533e-01,  ..., -1.1685e+00,\n",
       "           5.0701e-02, -1.7891e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.8369e+00, -6.0804e-01,  3.0813e-02,  ..., -1.4552e+00,\n",
       "          -3.6276e-02, -2.2396e+00],\n",
       "         [ 1.5435e+00, -7.6135e-01, -5.7152e-01,  ..., -1.5536e+00,\n",
       "          -1.3903e-01, -2.0707e+00],\n",
       "         [ 1.6890e+00,  4.7414e-02, -2.9263e-01,  ..., -1.3821e+00,\n",
       "          -2.0107e-01, -1.8481e+00],\n",
       "         ...,\n",
       "         [ 7.6624e-01, -3.3821e-01,  1.1113e-01,  ..., -1.3365e+00,\n",
       "          -3.8510e-01, -2.4213e+00],\n",
       "         [ 9.6113e-01, -5.0437e-01,  1.4046e-01,  ..., -1.1973e+00,\n",
       "          -1.1758e-01, -2.1948e+00],\n",
       "         [ 1.8226e+00, -3.0934e-01, -6.5669e-01,  ..., -7.1654e-01,\n",
       "          -4.1756e-01, -1.8676e+00]],\n",
       "\n",
       "        [[ 1.5159e+00, -3.4264e-01, -2.2424e-02,  ..., -1.1488e+00,\n",
       "           3.6153e-01, -1.9534e+00],\n",
       "         [ 1.4513e+00, -7.7292e-01,  3.5946e-01,  ..., -1.3808e+00,\n",
       "           1.3807e-01, -1.9425e+00],\n",
       "         [ 2.5313e+00, -3.6225e-01, -5.1710e-01,  ..., -1.1865e+00,\n",
       "          -1.6459e-01, -2.1511e+00],\n",
       "         ...,\n",
       "         [ 1.6981e+00,  6.0710e-02, -2.4188e-03,  ..., -8.6399e-01,\n",
       "          -5.7945e-01, -1.8746e+00],\n",
       "         [ 2.0212e+00, -5.5244e-01, -4.2869e-01,  ..., -1.4895e+00,\n",
       "          -9.2336e-02, -1.5785e+00],\n",
       "         [ 2.0332e+00, -1.5251e-01, -3.6172e-01,  ..., -1.0692e+00,\n",
       "           9.5764e-02, -1.5537e+00]],\n",
       "\n",
       "        [[ 1.5010e+00, -1.9680e-01, -2.4425e-01,  ..., -1.2165e+00,\n",
       "          -3.9950e-02, -2.0693e+00],\n",
       "         [ 1.7643e+00, -2.3302e-01, -2.5188e-01,  ..., -9.6443e-01,\n",
       "          -7.2803e-02, -1.8164e+00],\n",
       "         [ 1.8412e+00, -5.3774e-01, -7.3630e-02,  ..., -1.1697e+00,\n",
       "          -1.1863e-01, -2.1433e+00],\n",
       "         ...,\n",
       "         [ 1.5592e+00, -2.0097e-01,  2.8242e-01,  ..., -1.2167e+00,\n",
       "           1.5562e-01, -1.7122e+00],\n",
       "         [ 1.9060e+00, -4.4857e-01, -1.4461e-01,  ..., -1.3880e+00,\n",
       "           1.8092e-01, -1.7527e+00],\n",
       "         [ 1.6665e+00,  3.0297e-01, -4.7764e-01,  ..., -9.1305e-01,\n",
       "           1.5944e-01, -1.8722e+00]]], device='cuda:0',\n",
       "       grad_fn=<AsStridedBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = nn.Linear(100, 100)\n",
    "KL = KronLinear(100, 100, structured_sparse=False)\n",
    "\n",
    "input = torch.randn(256, 100, 100)\n",
    "L, KL = L.to('cuda'), KL.to('cuda')\n",
    "input = input.to('cuda')\n",
    "\n",
    "\n",
    "L_time = time.time()\n",
    "L(input)\n",
    "L_time = time.time() - L_time\n",
    "print(f\"L_time: {L_time}\")\n",
    "KL(input)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017093896865844727\n",
      "0.0011529922485351562\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time \n",
    "a = torch.randn(3, 1000, 2000)\n",
    "b = torch.randn(3, 2000, 1000)\n",
    "a, b = a.to('cuda'), b.to('cuda')\n",
    "start_time = time.time()\n",
    "c = torch.bmm(a, b)\n",
    "print(time.time() - start_time)\n",
    "start_time = time.time()\n",
    "for i in range(3):\n",
    "    c[i] = a[i] @ b[i]\n",
    "print(time.time() - start_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
