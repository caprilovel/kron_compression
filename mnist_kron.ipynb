{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from einops import rearrange, reduce, repeat\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch \n",
    "from gkpd import gkpd, KroneckerConv2d\n",
    "from gkpd.tensorops import kron\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available()\n",
    "# torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4096])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class KronLinear(nn.Module):\n",
    "    def __init__(self, rank, a_shape, b_shape, bias=True) -> None:\n",
    "        super().__init__()\n",
    "        self.rank = rank\n",
    "        self.s = nn.Parameter(torch.randn(*a_shape), requires_grad=True)\n",
    "        self.a = nn.Parameter(torch.randn(rank, *a_shape), requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.randn(rank, *b_shape), requires_grad=True)\n",
    "        nn.init.xavier_uniform_(self.a)\n",
    "        nn.init.xavier_uniform_(self.b)\n",
    "        bias_shape = np.multiply(a_shape, b_shape)\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(*bias_shape[1:]), requires_grad=True)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        a = self.s.unsqueeze(0) * self.a\n",
    "        w = kron(a, self.b)\n",
    "        \n",
    "        out = x @ w \n",
    "        if self.bias is not None:\n",
    "            out += self.bias.unsqueeze(0)\n",
    "        return out\n",
    "    \n",
    "# test module \n",
    "x = torch.randn(64, 256)\n",
    "m = KronLinear(10, (16, 64), (16, 64), bias=False)\n",
    "\n",
    "m(x).shape \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        \n",
    "class KronLeNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(KronLeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        rank1 = 21\n",
    "        rank2 = 10\n",
    "        rank3 = 4\n",
    "    \n",
    "        self.kronfc1 = KronLinear(rank1, (16, 10), (16, 12), bias=False)\n",
    "        \n",
    "        self.kronfc2 = KronLinear(rank2, (10, 12), (12, 7), bias=False)\n",
    "        self.kronfc3 = KronLinear(rank3, (12, 2), (7, 5), bias=False)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = self.relu3(self.kronfc1(x))\n",
    "        x = self.relu4(self.kronfc2(x))\n",
    "        x = self.kronfc3(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kl = KronLinear(2, (2, 2), (2, 2), bias=False)\n",
    "# optimizer = optim.Adam(kl.parameters(), lr=0.001)\n",
    "# for i in kl.parameters():\n",
    "#     print(i)\n",
    "# x = torch.randn(2, 4)\n",
    "# y = torch.randint(0, 2, (2, ))\n",
    "# kl(x).shape\n",
    "# loss = F.cross_entropy(kl(x), y)\n",
    "# loss.backward()\n",
    "\n",
    "# for i in kl.parameters():\n",
    "#     print(i.grad.numpy())\n",
    "# optimizer.step()\n",
    "# for i in kl.parameters():\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.relu4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# calculate the number of parameters in LeNet\n",
    "def count_parameter(model):\n",
    "    \n",
    "    total = 0\n",
    "    for i in model.parameters():\n",
    "        total += i.numel()\n",
    "    print(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12544\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = KronLeNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "count_parameter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inputs, labels in train_loader:\n",
    "#     inputs, labels = inputs.to(device), labels.to(device)\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = model(inputs)\n",
    "#     loss = criterion(outputs, labels)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     break\n",
    "# loss\n",
    "# for i in model.parameters():\n",
    "#     print(i.shape)\n",
    "# model.kronfc1.a.grad.cpu().numpy()\n",
    "def calculate_sparsity(model, threshold=1e-6):\n",
    "    total_params = 0\n",
    "    sparse_params = 0\n",
    "\n",
    "    for param in model.parameters():\n",
    "        total_params += param.numel()  # 统计参数总数\n",
    "        sparse_params += torch.sum(torch.abs(param) < threshold).item()  # 统计绝对值小于阈值的参数数量\n",
    "\n",
    "    sparsity = sparse_params / total_params  # 计算稀疏性\n",
    "    return sparsity, sparse_params, total_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epochs, l1_weight=0.01):\n",
    "    decay_weight = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "    weight1 = l1_weight\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        l1_weight = decay_weight[epoch//20] * weight1\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs, outputs.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss += l1_weight * torch.norm(model.kronfc1.s, p=1)\n",
    "            loss += l1_weight * torch.norm(model.kronfc2.s, p=1)\n",
    "            loss += l1_weight * torch.norm(model.kronfc3.s, p=1)\n",
    "            \n",
    "            # print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "        # print the sparsity of a, dont use == use the abs less than 1e-5\n",
    "        print(calculate_sparsity(model))\n",
    "        # calcu the s sparsity\n",
    "        fc1_sparse = torch.sum(torch.abs(model.kronfc1.s) < 1e-5).item() \n",
    "        fc2_sparse = torch.sum(torch.abs(model.kronfc2.s) < 1e-5).item() \n",
    "        fc3_sparse = torch.sum(torch.abs(model.kronfc3.s) < 1e-5).item() \n",
    "        # total_params = model.kronfc1.s.numel() + model.kronfc2.s.numel() + model.kronfc3.s.numel()\n",
    "        \n",
    "        print(f\"fc1 sparsity: {fc1_sparse}, fc2 sparsity: {fc2_sparse}, fc3 sparsity: {fc3_sparse}\")\n",
    "        print(f\"total sparse params: {fc1_sparse + fc2_sparse + fc3_sparse}\")\n",
    "        # print(f\"fc1 total params: {model.kronfc1.s.numel()}, fc2 total params: {model.kronfc2.s.numel()}, fc3 total params: {model.kronfc3.s.numel()}\")\n",
    "        # print(f\"total params: {total_params}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 4.574455800086959\n",
      "(0.0, 0, 12544)\n",
      "fc1 sparsity: 0, fc2 sparsity: 2, fc3 sparsity: 0\n",
      "total sparse params: 2\n",
      "Epoch 2/100, Loss: 4.304711117673276\n",
      "(0.0, 0, 12544)\n",
      "fc1 sparsity: 1, fc2 sparsity: 2, fc3 sparsity: 0\n",
      "total sparse params: 3\n",
      "Epoch 3/100, Loss: 3.6294926471039175\n",
      "(7.971938775510203e-05, 1, 12544)\n",
      "fc1 sparsity: 3, fc2 sparsity: 3, fc3 sparsity: 0\n",
      "total sparse params: 6\n",
      "Epoch 4/100, Loss: 2.1339125919189534\n",
      "(7.971938775510203e-05, 1, 12544)\n",
      "fc1 sparsity: 1, fc2 sparsity: 3, fc3 sparsity: 1\n",
      "total sparse params: 5\n",
      "Epoch 5/100, Loss: 1.651762590352406\n",
      "(0.0, 0, 12544)\n",
      "fc1 sparsity: 10, fc2 sparsity: 3, fc3 sparsity: 1\n",
      "total sparse params: 14\n",
      "Epoch 6/100, Loss: 1.41234271511086\n",
      "(0.0, 0, 12544)\n",
      "fc1 sparsity: 4, fc2 sparsity: 6, fc3 sparsity: 1\n",
      "total sparse params: 11\n",
      "Epoch 7/100, Loss: 1.2173531121536614\n",
      "(0.00047831632653061223, 6, 12544)\n",
      "fc1 sparsity: 10, fc2 sparsity: 5, fc3 sparsity: 1\n",
      "total sparse params: 16\n",
      "Epoch 8/100, Loss: 1.055313567108691\n",
      "(7.971938775510203e-05, 1, 12544)\n",
      "fc1 sparsity: 5, fc2 sparsity: 4, fc3 sparsity: 0\n",
      "total sparse params: 9\n",
      "Epoch 9/100, Loss: 0.9173707724380087\n",
      "(0.00023915816326530612, 3, 12544)\n",
      "fc1 sparsity: 6, fc2 sparsity: 9, fc3 sparsity: 1\n",
      "total sparse params: 16\n",
      "Epoch 10/100, Loss: 0.7995098522985413\n",
      "(7.971938775510203e-05, 1, 12544)\n",
      "fc1 sparsity: 8, fc2 sparsity: 11, fc3 sparsity: 1\n",
      "total sparse params: 20\n",
      "Epoch 11/100, Loss: 0.6987455057691155\n",
      "(0.00015943877551020407, 2, 12544)\n",
      "fc1 sparsity: 7, fc2 sparsity: 7, fc3 sparsity: 1\n",
      "total sparse params: 15\n",
      "Epoch 12/100, Loss: 0.6108357844385766\n",
      "(7.971938775510203e-05, 1, 12544)\n",
      "fc1 sparsity: 3, fc2 sparsity: 8, fc3 sparsity: 3\n",
      "total sparse params: 14\n",
      "Epoch 13/100, Loss: 0.5303816617424808\n",
      "(0.00015943877551020407, 2, 12544)\n",
      "fc1 sparsity: 7, fc2 sparsity: 6, fc3 sparsity: 1\n",
      "total sparse params: 14\n",
      "Epoch 14/100, Loss: 0.4624924096407921\n",
      "(0.00015943877551020407, 2, 12544)\n",
      "fc1 sparsity: 10, fc2 sparsity: 7, fc3 sparsity: 2\n",
      "total sparse params: 19\n",
      "Epoch 15/100, Loss: 0.40387385527589426\n",
      "(0.00015943877551020407, 2, 12544)\n",
      "fc1 sparsity: 4, fc2 sparsity: 9, fc3 sparsity: 3\n",
      "total sparse params: 16\n",
      "Epoch 16/100, Loss: 0.351369335421367\n",
      "(0.00015943877551020407, 2, 12544)\n",
      "fc1 sparsity: 6, fc2 sparsity: 8, fc3 sparsity: 4\n",
      "total sparse params: 18\n",
      "Epoch 17/100, Loss: 0.30734914012237396\n",
      "(7.971938775510203e-05, 1, 12544)\n",
      "fc1 sparsity: 5, fc2 sparsity: 8, fc3 sparsity: 2\n",
      "total sparse params: 15\n",
      "Epoch 18/100, Loss: 0.2699531213815278\n",
      "(0.00015943877551020407, 2, 12544)\n",
      "fc1 sparsity: 7, fc2 sparsity: 8, fc3 sparsity: 2\n",
      "total sparse params: 17\n",
      "Epoch 19/100, Loss: 0.24124774243086894\n",
      "(7.971938775510203e-05, 1, 12544)\n",
      "fc1 sparsity: 5, fc2 sparsity: 10, fc3 sparsity: 2\n",
      "total sparse params: 17\n",
      "Epoch 20/100, Loss: 0.21995288964464213\n",
      "(7.971938775510203e-05, 1, 12544)\n",
      "fc1 sparsity: 3, fc2 sparsity: 12, fc3 sparsity: 3\n",
      "total sparse params: 18\n",
      "Epoch 21/100, Loss: 0.0872968563031572\n",
      "(0.0023915816326530613, 30, 12544)\n",
      "fc1 sparsity: 129, fc2 sparsity: 104, fc3 sparsity: 15\n",
      "total sparse params: 248\n",
      "Epoch 22/100, Loss: 0.0856303063703816\n",
      "(0.0023915816326530613, 30, 12544)\n",
      "fc1 sparsity: 127, fc2 sparsity: 104, fc3 sparsity: 16\n",
      "total sparse params: 247\n",
      "Epoch 23/100, Loss: 0.08274858774565684\n",
      "(0.0024713010204081634, 31, 12544)\n",
      "fc1 sparsity: 132, fc2 sparsity: 107, fc3 sparsity: 16\n",
      "total sparse params: 255\n",
      "Epoch 24/100, Loss: 0.08046580069283368\n",
      "(0.0024713010204081634, 31, 12544)\n",
      "fc1 sparsity: 131, fc2 sparsity: 104, fc3 sparsity: 17\n",
      "total sparse params: 252\n",
      "Epoch 25/100, Loss: 0.07818300726174164\n",
      "(0.0024713010204081634, 31, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 106, fc3 sparsity: 18\n",
      "total sparse params: 250\n",
      "Epoch 26/100, Loss: 0.07663657780744627\n",
      "(0.0023915816326530613, 30, 12544)\n",
      "fc1 sparsity: 128, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 250\n",
      "Epoch 27/100, Loss: 0.07466244603644238\n",
      "(0.002551020408163265, 32, 12544)\n",
      "fc1 sparsity: 130, fc2 sparsity: 109, fc3 sparsity: 18\n",
      "total sparse params: 257\n",
      "Epoch 28/100, Loss: 0.07314265077449143\n",
      "(0.002072704081632653, 26, 12544)\n",
      "fc1 sparsity: 128, fc2 sparsity: 104, fc3 sparsity: 16\n",
      "total sparse params: 248\n",
      "Epoch 29/100, Loss: 0.07160659640558811\n",
      "(0.002232142857142857, 28, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 109, fc3 sparsity: 16\n",
      "total sparse params: 251\n",
      "Epoch 30/100, Loss: 0.0705243614085241\n",
      "(0.002232142857142857, 28, 12544)\n",
      "fc1 sparsity: 131, fc2 sparsity: 106, fc3 sparsity: 15\n",
      "total sparse params: 252\n",
      "Epoch 31/100, Loss: 0.0689886342128441\n",
      "(0.0023915816326530613, 30, 12544)\n",
      "fc1 sparsity: 130, fc2 sparsity: 109, fc3 sparsity: 17\n",
      "total sparse params: 256\n",
      "Epoch 32/100, Loss: 0.06781572197029777\n",
      "(0.002232142857142857, 28, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 107, fc3 sparsity: 17\n",
      "total sparse params: 250\n",
      "Epoch 33/100, Loss: 0.06666268721850378\n",
      "(0.0024713010204081634, 31, 12544)\n",
      "fc1 sparsity: 133, fc2 sparsity: 108, fc3 sparsity: 17\n",
      "total sparse params: 258\n",
      "Epoch 34/100, Loss: 0.06524662619957061\n",
      "(0.002311862244897959, 29, 12544)\n",
      "fc1 sparsity: 128, fc2 sparsity: 106, fc3 sparsity: 17\n",
      "total sparse params: 251\n",
      "Epoch 35/100, Loss: 0.06399907128635182\n",
      "(0.002232142857142857, 28, 12544)\n",
      "fc1 sparsity: 131, fc2 sparsity: 110, fc3 sparsity: 17\n",
      "total sparse params: 258\n",
      "Epoch 36/100, Loss: 0.06340234256240287\n",
      "(0.002311862244897959, 29, 12544)\n",
      "fc1 sparsity: 127, fc2 sparsity: 106, fc3 sparsity: 16\n",
      "total sparse params: 249\n",
      "Epoch 37/100, Loss: 0.06243412064582999\n",
      "(0.002152423469387755, 27, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 106, fc3 sparsity: 16\n",
      "total sparse params: 248\n",
      "Epoch 38/100, Loss: 0.06140920175894746\n",
      "(0.002311862244897959, 29, 12544)\n",
      "fc1 sparsity: 129, fc2 sparsity: 111, fc3 sparsity: 18\n",
      "total sparse params: 258\n",
      "Epoch 39/100, Loss: 0.06051529230458586\n",
      "(0.002152423469387755, 27, 12544)\n",
      "fc1 sparsity: 130, fc2 sparsity: 110, fc3 sparsity: 18\n",
      "total sparse params: 258\n",
      "Epoch 40/100, Loss: 0.058903605795340305\n",
      "(0.002152423469387755, 27, 12544)\n",
      "fc1 sparsity: 132, fc2 sparsity: 109, fc3 sparsity: 18\n",
      "total sparse params: 259\n",
      "Epoch 41/100, Loss: 0.04755902576517425\n",
      "(0.0196109693877551, 246, 12544)\n",
      "fc1 sparsity: 127, fc2 sparsity: 106, fc3 sparsity: 16\n",
      "total sparse params: 249\n",
      "Epoch 42/100, Loss: 0.04666184811348489\n",
      "(0.019770408163265307, 248, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 106, fc3 sparsity: 17\n",
      "total sparse params: 249\n",
      "Epoch 43/100, Loss: 0.04561682898841147\n",
      "(0.0196109693877551, 246, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 106, fc3 sparsity: 18\n",
      "total sparse params: 250\n",
      "Epoch 44/100, Loss: 0.04523092296584122\n",
      "(0.01992984693877551, 250, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 107, fc3 sparsity: 17\n",
      "total sparse params: 250\n",
      "Epoch 45/100, Loss: 0.044733149136778026\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 106, fc3 sparsity: 17\n",
      "total sparse params: 249\n",
      "Epoch 46/100, Loss: 0.04383407111901706\n",
      "(0.019690688775510203, 247, 12544)\n",
      "fc1 sparsity: 128, fc2 sparsity: 106, fc3 sparsity: 17\n",
      "total sparse params: 251\n",
      "Epoch 47/100, Loss: 0.0432792230497307\n",
      "(0.01985012755102041, 249, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 107, fc3 sparsity: 17\n",
      "total sparse params: 250\n",
      "Epoch 48/100, Loss: 0.042794083641506414\n",
      "(0.019690688775510203, 247, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 107, fc3 sparsity: 17\n",
      "total sparse params: 250\n",
      "Epoch 49/100, Loss: 0.042740098630904215\n",
      "(0.0194515306122449, 244, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 107, fc3 sparsity: 17\n",
      "total sparse params: 250\n",
      "Epoch 50/100, Loss: 0.0421047278469913\n",
      "(0.0196109693877551, 246, 12544)\n",
      "fc1 sparsity: 127, fc2 sparsity: 106, fc3 sparsity: 18\n",
      "total sparse params: 251\n",
      "Epoch 51/100, Loss: 0.04101611308240667\n",
      "(0.019770408163265307, 248, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 108, fc3 sparsity: 17\n",
      "total sparse params: 251\n",
      "Epoch 52/100, Loss: 0.04096174840433106\n",
      "(0.0196109693877551, 246, 12544)\n",
      "fc1 sparsity: 128, fc2 sparsity: 106, fc3 sparsity: 16\n",
      "total sparse params: 250\n",
      "Epoch 53/100, Loss: 0.0404445234421037\n",
      "(0.019770408163265307, 248, 12544)\n",
      "fc1 sparsity: 127, fc2 sparsity: 107, fc3 sparsity: 17\n",
      "total sparse params: 251\n",
      "Epoch 54/100, Loss: 0.039386597808762226\n",
      "(0.019770408163265307, 248, 12544)\n",
      "fc1 sparsity: 127, fc2 sparsity: 106, fc3 sparsity: 16\n",
      "total sparse params: 249\n",
      "Epoch 55/100, Loss: 0.03924836575595746\n",
      "(0.019770408163265307, 248, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 107, fc3 sparsity: 17\n",
      "total sparse params: 250\n",
      "Epoch 56/100, Loss: 0.038884252361925456\n",
      "(0.0194515306122449, 244, 12544)\n",
      "fc1 sparsity: 127, fc2 sparsity: 106, fc3 sparsity: 18\n",
      "total sparse params: 251\n",
      "Epoch 57/100, Loss: 0.03826804222466587\n",
      "(0.019690688775510203, 247, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 106, fc3 sparsity: 18\n",
      "total sparse params: 250\n",
      "Epoch 58/100, Loss: 0.03790678700674444\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 107, fc3 sparsity: 18\n",
      "total sparse params: 251\n",
      "Epoch 59/100, Loss: 0.03724339503501016\n",
      "(0.019690688775510203, 247, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 107, fc3 sparsity: 18\n",
      "total sparse params: 251\n",
      "Epoch 60/100, Loss: 0.037299916383746794\n",
      "(0.019770408163265307, 248, 12544)\n",
      "fc1 sparsity: 128, fc2 sparsity: 108, fc3 sparsity: 17\n",
      "total sparse params: 253\n",
      "Epoch 61/100, Loss: 0.035146975495441976\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 16\n",
      "total sparse params: 245\n",
      "Epoch 62/100, Loss: 0.03473893448064821\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 248\n",
      "Epoch 63/100, Loss: 0.03450054706790165\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 125, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 247\n",
      "Epoch 64/100, Loss: 0.03450179847815796\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 125, fc2 sparsity: 105, fc3 sparsity: 16\n",
      "total sparse params: 246\n",
      "Epoch 65/100, Loss: 0.033331059216983865\n",
      "(0.0194515306122449, 244, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 248\n",
      "Epoch 66/100, Loss: 0.03392652849693334\n",
      "(0.019690688775510203, 247, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 106, fc3 sparsity: 17\n",
      "total sparse params: 249\n",
      "Epoch 67/100, Loss: 0.03293189439814719\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 125, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 247\n",
      "Epoch 68/100, Loss: 0.032583125346059255\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 127, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 249\n",
      "Epoch 69/100, Loss: 0.032260290283991744\n",
      "(0.0196109693877551, 246, 12544)\n",
      "fc1 sparsity: 127, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 249\n",
      "Epoch 70/100, Loss: 0.03221418577608025\n",
      "(0.0194515306122449, 244, 12544)\n",
      "fc1 sparsity: 125, fc2 sparsity: 105, fc3 sparsity: 16\n",
      "total sparse params: 246\n",
      "Epoch 71/100, Loss: 0.031657216483822664\n",
      "(0.0196109693877551, 246, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 248\n",
      "Epoch 72/100, Loss: 0.03143187738270057\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 107, fc3 sparsity: 17\n",
      "total sparse params: 248\n",
      "Epoch 73/100, Loss: 0.030536169594649953\n",
      "(0.0196109693877551, 246, 12544)\n",
      "fc1 sparsity: 125, fc2 sparsity: 106, fc3 sparsity: 16\n",
      "total sparse params: 247\n",
      "Epoch 74/100, Loss: 0.03079787259343078\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 246\n",
      "Epoch 75/100, Loss: 0.030732292018625745\n",
      "(0.0196109693877551, 246, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 106, fc3 sparsity: 17\n",
      "total sparse params: 249\n",
      "Epoch 76/100, Loss: 0.030263808331509896\n",
      "(0.0196109693877551, 246, 12544)\n",
      "fc1 sparsity: 127, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 249\n",
      "Epoch 77/100, Loss: 0.02951487629659606\n",
      "(0.019371811224489797, 243, 12544)\n",
      "fc1 sparsity: 125, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 247\n",
      "Epoch 78/100, Loss: 0.029023822574191907\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 125, fc2 sparsity: 105, fc3 sparsity: 16\n",
      "total sparse params: 246\n",
      "Epoch 79/100, Loss: 0.02916690881739729\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 106, fc3 sparsity: 16\n",
      "total sparse params: 246\n",
      "Epoch 80/100, Loss: 0.0292422973669009\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 126, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 248\n",
      "Epoch 81/100, Loss: 0.02814044828846042\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 106, fc3 sparsity: 17\n",
      "total sparse params: 247\n",
      "Epoch 82/100, Loss: 0.02813934333281339\n",
      "(0.019292091836734693, 242, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 246\n",
      "Epoch 83/100, Loss: 0.02775099677034529\n",
      "(0.0194515306122449, 244, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 246\n",
      "Epoch 84/100, Loss: 0.027657452909525846\n",
      "(0.01913265306122449, 240, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 246\n",
      "Epoch 85/100, Loss: 0.027350506125689934\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 246\n",
      "Epoch 86/100, Loss: 0.02690141900615178\n",
      "(0.0194515306122449, 244, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 16\n",
      "total sparse params: 245\n",
      "Epoch 87/100, Loss: 0.026472290689147686\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 246\n",
      "Epoch 88/100, Loss: 0.0266184489194826\n",
      "(0.019292091836734693, 242, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 16\n",
      "total sparse params: 245\n",
      "Epoch 89/100, Loss: 0.026527166769904114\n",
      "(0.019371811224489797, 243, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 16\n",
      "total sparse params: 245\n",
      "Epoch 90/100, Loss: 0.025579514359450415\n",
      "(0.019292091836734693, 242, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 16\n",
      "total sparse params: 245\n",
      "Epoch 91/100, Loss: 0.025918292015223013\n",
      "(0.019292091836734693, 242, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 106, fc3 sparsity: 16\n",
      "total sparse params: 246\n",
      "Epoch 92/100, Loss: 0.02567335487420195\n",
      "(0.019292091836734693, 242, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 246\n",
      "Epoch 93/100, Loss: 0.025302093355049654\n",
      "(0.019371811224489797, 243, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 16\n",
      "total sparse params: 245\n",
      "Epoch 94/100, Loss: 0.02479495278544794\n",
      "(0.019371811224489797, 243, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 16\n",
      "total sparse params: 245\n",
      "Epoch 95/100, Loss: 0.024283263508806566\n",
      "(0.0194515306122449, 244, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 16\n",
      "total sparse params: 245\n",
      "Epoch 96/100, Loss: 0.02449169019668133\n",
      "(0.01913265306122449, 240, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 17\n",
      "total sparse params: 246\n",
      "Epoch 97/100, Loss: 0.02427504161368561\n",
      "(0.01921237244897959, 241, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 106, fc3 sparsity: 16\n",
      "total sparse params: 246\n",
      "Epoch 98/100, Loss: 0.0238649773813942\n",
      "(0.01921237244897959, 241, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 16\n",
      "total sparse params: 245\n",
      "Epoch 99/100, Loss: 0.024006029762298382\n",
      "(0.019371811224489797, 243, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 105, fc3 sparsity: 16\n",
      "total sparse params: 245\n",
      "Epoch 100/100, Loss: 0.02349188083977707\n",
      "(0.01953125, 245, 12544)\n",
      "fc1 sparsity: 124, fc2 sparsity: 106, fc3 sparsity: 17\n",
      "total sparse params: 247\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, criterion, optimizer, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "    print(f\"Accuracy: {100 * correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.45999908447266\n"
     ]
    }
   ],
   "source": [
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KronLeNet' object has no attribute 'fc1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m weight1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m      2\u001b[0m weight2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m      3\u001b[0m weight3 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc3\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KronLeNet' object has no attribute 'fc1'"
     ]
    }
   ],
   "source": [
    "weight1 = model.fc1.weight.data.detach()\n",
    "weight2 = model.fc2.weight.data.detach()\n",
    "weight3 = model.fc3.weight.data.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21644"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcu the nums of the three weight matrix\n",
    "params = 0\n",
    "for i in model.parameters():\n",
    "    params += i.numel()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 256]) torch.Size([84, 120]) torch.Size([10, 84])\n"
     ]
    }
   ],
   "source": [
    "print(weight1.shape, weight2.shape, weight3.shape)\n",
    "w11_shape = [10, 16] \n",
    "w12_shape = [12, 16]\n",
    "w21_shape = [7, 12]\n",
    "w22_shape = [12, 10]\n",
    "w31_shape = [5, 7]\n",
    "w32_shape = [2, 12]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([152, 10, 16]),\n",
       " torch.Size([152, 12, 16]),\n",
       " torch.Size([84, 7, 12]),\n",
       " torch.Size([84, 12, 10]),\n",
       " torch.Size([24, 5, 7]),\n",
       " torch.Size([24, 2, 12]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = 50 # 160\n",
    "w11_hat, w12_hat = gkpd(weight1, w11_shape, w12_shape, atol=1e-1)\n",
    "r2 = 31 # 84\n",
    "w21_hat, w22_hat = gkpd(weight2, w21_shape, w22_shape, atol=1e-1)\n",
    "r3 = 8 # 24\n",
    "w31_hat, w32_hat = gkpd(weight3, w31_shape, w32_shape, atol=1e-1)\n",
    "w11_hat.shape, w12_hat.shape, w21_hat.shape, w22_hat.shape, w31_hat.shape, w32_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24396"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcu the nums of the six weight matrix\n",
    "params = 0\n",
    "for i in [w11_hat[0:r1,], w12_hat[0:r1,], w21_hat[0:r2,], w22_hat[0:r2,], w31_hat[0:r3,], w32_hat[0:r3,]]:\n",
    "    params += i.numel()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.9000015258789\n"
     ]
    }
   ],
   "source": [
    "w1_hat = kron(w11_hat[0:r1], w12_hat[0:r1])\n",
    "w2_hat = kron(w21_hat[0:r2], w22_hat[0:r2]) \n",
    "w3_hat = kron(w31_hat[0:r3], w32_hat[0:r3])\n",
    "model.fc1.weight.data = w1_hat\n",
    "model.fc2.weight.data = w2_hat\n",
    "model.fc3.weight.data = w3_hat\n",
    "model = model.to(device)\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "w111_shape, w112_shape = [16, 2, 4], [10, 5, 4]\n",
    "w211_shape, w212_shape = [28, 1, 3], [3, 7, 4]\n",
    "w311_shape, w312_shape = [4, 1, 7], [6, 5, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = 64 # 128\n",
    "w111_hat, w112_hat = gkpd(w11_hat, w111_shape, w112_shape)\n",
    "r2 = 41 # 83\n",
    "w211_hat, w212_hat = gkpd(w21_hat, w211_shape, w212_shape)\n",
    "w211_hat.shape\n",
    "r3 = 14 # 28\n",
    "w311_hat, w312_hat = gkpd(w31_hat, w311_shape, w312_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70068"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcu the nums of the 9 weight matrix\n",
    "params = 0\n",
    "for i in [w111_hat[0:r1,], w112_hat[0:r1,], w211_hat[0:r2,], w212_hat[0:r2,], w311_hat[0:r3,], w312_hat[0:r3,]]:\n",
    "    params += i.numel()\n",
    "for i in [w12_hat, w22_hat, w32_hat]:\n",
    "    params += i.numel()\n",
    "params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_transpose(param):\n",
    "    N,_,_ = param.shape\n",
    "    return torch.reshape(param, (N, -1)).T\n",
    "a = torch.randn(2, 3, 4)\n",
    "group_transpose(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nohup python -u main.py > log.txt 2>&1 &"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
