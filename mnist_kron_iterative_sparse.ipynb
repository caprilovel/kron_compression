{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from einops import rearrange, reduce, repeat\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch \n",
    "from gkpd import gkpd, KroneckerConv2d\n",
    "from gkpd.tensorops import kron\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available()\n",
    "# torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4096])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class KronLinear(nn.Module):\n",
    "    def __init__(self, rank, a_shape, b_shape, bias=True) -> None:\n",
    "        super().__init__()\n",
    "        self.rank = rank\n",
    "        self.s = nn.Parameter(torch.randn(*a_shape), requires_grad=True)\n",
    "        self.a = nn.Parameter(torch.randn(rank, *a_shape), requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.randn(rank, *b_shape), requires_grad=True)\n",
    "        nn.init.xavier_uniform_(self.a)\n",
    "        nn.init.xavier_uniform_(self.b)\n",
    "        bias_shape = np.multiply(a_shape, b_shape)\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.randn(*bias_shape[1:]), requires_grad=True)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        a = self.s.unsqueeze(0) * self.a\n",
    "        w = kron(a, self.b)\n",
    "        \n",
    "        out = x @ w \n",
    "        if self.bias is not None:\n",
    "            out += self.bias.unsqueeze(0)\n",
    "        return out\n",
    "    \n",
    "# test module \n",
    "x = torch.randn(64, 256)\n",
    "m = KronLinear(10, (16, 64), (16, 64), bias=False)\n",
    "\n",
    "m(x).shape \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        \n",
    "class KronLeNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(KronLeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        rank1 = 21\n",
    "        rank2 = 10\n",
    "        rank3 = 4\n",
    "    \n",
    "        self.kronfc1 = KronLinear(rank1, (16, 10), (16, 12), bias=False)\n",
    "        \n",
    "        self.kronfc2 = KronLinear(rank2, (10, 12), (12, 7), bias=False)\n",
    "        self.kronfc3 = KronLinear(rank3, (12, 2), (7, 5), bias=False)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = self.relu3(self.kronfc1(x))\n",
    "        x = self.relu4(self.kronfc2(x))\n",
    "        x = self.kronfc3(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kl = KronLinear(2, (2, 2), (2, 2), bias=False)\n",
    "# optimizer = optim.Adam(kl.parameters(), lr=0.001)\n",
    "# for i in kl.parameters():\n",
    "#     print(i)\n",
    "# x = torch.randn(2, 4)\n",
    "# y = torch.randint(0, 2, (2, ))\n",
    "# kl(x).shape\n",
    "# loss = F.cross_entropy(kl(x), y)\n",
    "# loss.backward()\n",
    "\n",
    "# for i in kl.parameters():\n",
    "#     print(i.grad.numpy())\n",
    "# optimizer.step()\n",
    "# for i in kl.parameters():\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.relu4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# calculate the number of parameters in LeNet\n",
    "def count_parameter(model):\n",
    "    \n",
    "    total = 0\n",
    "    for i in model.parameters():\n",
    "        total += i.numel()\n",
    "    print(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12544\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = KronLeNet().to(device)\n",
    "mask1 = torch.ones_like(model.kronfc1.s)\n",
    "mask2 = torch.ones_like(model.kronfc2.s)\n",
    "mask3 = torch.ones_like(model.kronfc3.s)\n",
    "mask1, mask2, mask3 = mask1.to(device), mask2.to(device), mask3.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "count_parameter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inputs, labels in train_loader:\n",
    "#     inputs, labels = inputs.to(device), labels.to(device)\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = model(inputs)\n",
    "#     loss = criterion(outputs, labels)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     break\n",
    "# loss\n",
    "# for i in model.parameters():\n",
    "#     print(i.shape)\n",
    "# model.kronfc1.a.grad.cpu().numpy()\n",
    "def calculate_sparsity(model, threshold=1e-6):\n",
    "    total_params = 0\n",
    "    sparse_params = 0\n",
    "\n",
    "    for param in model.parameters():\n",
    "        total_params += param.numel()  # 统计参数总数\n",
    "        sparse_params += torch.sum(torch.abs(param) < threshold).item()  # 统计绝对值小于阈值的参数数量\n",
    "\n",
    "    sparsity = sparse_params / total_params  # 计算稀疏性\n",
    "    return sparsity, sparse_params, total_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epochs, l1_weight=0.01):\n",
    "    decay_weight = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "    weight1 = l1_weight\n",
    "    for epoch in range(epochs):\n",
    "        if epoch % 5 == 0:\n",
    "            mask1 = mask1 * (torch.abs(model.kronfc1.s) > 1e-5).float()\n",
    "            model.kronfc1.s.data = model.kronfc1.s.data * mask1\n",
    "            mask2 = mask2 * (torch.abs(model.kronfc2.s) > 1e-5).float()\n",
    "            model.kronfc2.s.data = model.kronfc2.s.data * mask2\n",
    "            mask3 = mask3 * (torch.abs(model.kronfc3.s) > 1e-5).float()\n",
    "            model.kronfc3.s.data = model.kronfc3.s.data * mask3\n",
    "            \n",
    "        running_loss = 0.0\n",
    "        l1_weight = decay_weight[epoch//20] * weight1\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # print(outputs, outputs.shape)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss += l1_weight * torch.norm(model.kronfc1.s, p=1)\n",
    "            loss += l1_weight * torch.norm(model.kronfc2.s, p=1)\n",
    "            loss += l1_weight * torch.norm(model.kronfc3.s, p=1)\n",
    "            \n",
    "            # print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "        # print the sparsity of a, dont use == use the abs less than 1e-5\n",
    "        print(calculate_sparsity(model))\n",
    "        # calcu the s sparsity\n",
    "        fc1_sparse = torch.sum(torch.abs(model.kronfc1.s) < 1e-5).item() \n",
    "        fc2_sparse = torch.sum(torch.abs(model.kronfc2.s) < 1e-5).item() \n",
    "        fc3_sparse = torch.sum(torch.abs(model.kronfc3.s) < 1e-5).item() \n",
    "        # total_params = model.kronfc1.s.numel() + model.kronfc2.s.numel() + model.kronfc3.s.numel()\n",
    "        \n",
    "        print(f\"fc1 sparsity: {fc1_sparse}, fc2 sparsity: {fc2_sparse}, fc3 sparsity: {fc3_sparse}\")\n",
    "        print(f\"total sparse params: {fc1_sparse + fc2_sparse + fc3_sparse}\")\n",
    "        # print(f\"fc1 total params: {model.kronfc1.s.numel()}, fc2 total params: {model.kronfc2.s.numel()}, fc3 total params: {model.kronfc3.s.numel()}\")\n",
    "        # print(f\"total params: {total_params}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'mask1' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(model, train_loader, criterion, optimizer, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, epochs, l1_weight)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 6\u001b[0m         mask1 \u001b[38;5;241m=\u001b[39m mask1 \u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39mabs(model\u001b[38;5;241m.\u001b[39mkronfc1\u001b[38;5;241m.\u001b[39ms) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1e-5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      7\u001b[0m         model\u001b[38;5;241m.\u001b[39mkronfc1\u001b[38;5;241m.\u001b[39ms\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mkronfc1\u001b[38;5;241m.\u001b[39ms\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m*\u001b[39m mask1\n\u001b[1;32m      8\u001b[0m         mask2 \u001b[38;5;241m=\u001b[39m mask2 \u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39mabs(model\u001b[38;5;241m.\u001b[39mkronfc2\u001b[38;5;241m.\u001b[39ms) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1e-5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'mask1' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, criterion, optimizer, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "    print(f\"Accuracy: {100 * correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.45999908447266\n"
     ]
    }
   ],
   "source": [
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KronLeNet' object has no attribute 'fc1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m weight1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m      2\u001b[0m weight2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m      3\u001b[0m weight3 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc3\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KronLeNet' object has no attribute 'fc1'"
     ]
    }
   ],
   "source": [
    "weight1 = model.fc1.weight.data.detach()\n",
    "weight2 = model.fc2.weight.data.detach()\n",
    "weight3 = model.fc3.weight.data.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21644"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcu the nums of the three weight matrix\n",
    "params = 0\n",
    "for i in model.parameters():\n",
    "    params += i.numel()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 256]) torch.Size([84, 120]) torch.Size([10, 84])\n"
     ]
    }
   ],
   "source": [
    "print(weight1.shape, weight2.shape, weight3.shape)\n",
    "w11_shape = [10, 16] \n",
    "w12_shape = [12, 16]\n",
    "w21_shape = [7, 12]\n",
    "w22_shape = [12, 10]\n",
    "w31_shape = [5, 7]\n",
    "w32_shape = [2, 12]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([152, 10, 16]),\n",
       " torch.Size([152, 12, 16]),\n",
       " torch.Size([84, 7, 12]),\n",
       " torch.Size([84, 12, 10]),\n",
       " torch.Size([24, 5, 7]),\n",
       " torch.Size([24, 2, 12]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = 50 # 160\n",
    "w11_hat, w12_hat = gkpd(weight1, w11_shape, w12_shape, atol=1e-1)\n",
    "r2 = 31 # 84\n",
    "w21_hat, w22_hat = gkpd(weight2, w21_shape, w22_shape, atol=1e-1)\n",
    "r3 = 8 # 24\n",
    "w31_hat, w32_hat = gkpd(weight3, w31_shape, w32_shape, atol=1e-1)\n",
    "w11_hat.shape, w12_hat.shape, w21_hat.shape, w22_hat.shape, w31_hat.shape, w32_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24396"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcu the nums of the six weight matrix\n",
    "params = 0\n",
    "for i in [w11_hat[0:r1,], w12_hat[0:r1,], w21_hat[0:r2,], w22_hat[0:r2,], w31_hat[0:r3,], w32_hat[0:r3,]]:\n",
    "    params += i.numel()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.9000015258789\n"
     ]
    }
   ],
   "source": [
    "w1_hat = kron(w11_hat[0:r1], w12_hat[0:r1])\n",
    "w2_hat = kron(w21_hat[0:r2], w22_hat[0:r2]) \n",
    "w3_hat = kron(w31_hat[0:r3], w32_hat[0:r3])\n",
    "model.fc1.weight.data = w1_hat\n",
    "model.fc2.weight.data = w2_hat\n",
    "model.fc3.weight.data = w3_hat\n",
    "model = model.to(device)\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "w111_shape, w112_shape = [16, 2, 4], [10, 5, 4]\n",
    "w211_shape, w212_shape = [28, 1, 3], [3, 7, 4]\n",
    "w311_shape, w312_shape = [4, 1, 7], [6, 5, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = 64 # 128\n",
    "w111_hat, w112_hat = gkpd(w11_hat, w111_shape, w112_shape)\n",
    "r2 = 41 # 83\n",
    "w211_hat, w212_hat = gkpd(w21_hat, w211_shape, w212_shape)\n",
    "w211_hat.shape\n",
    "r3 = 14 # 28\n",
    "w311_hat, w312_hat = gkpd(w31_hat, w311_shape, w312_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70068"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcu the nums of the 9 weight matrix\n",
    "params = 0\n",
    "for i in [w111_hat[0:r1,], w112_hat[0:r1,], w211_hat[0:r2,], w212_hat[0:r2,], w311_hat[0:r3,], w312_hat[0:r3,]]:\n",
    "    params += i.numel()\n",
    "for i in [w12_hat, w22_hat, w32_hat]:\n",
    "    params += i.numel()\n",
    "params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_transpose(param):\n",
    "    N,_,_ = param.shape\n",
    "    return torch.reshape(param, (N, -1)).T\n",
    "a = torch.randn(2, 3, 4)\n",
    "group_transpose(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nohup python -u main.py > log.txt 2>&1 &"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
